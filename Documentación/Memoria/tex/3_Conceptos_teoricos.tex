\capitulo{3}{Conceptos teóricos}

\section{Implementación hardware}
En este proyecto trabajaremos con AGVs. Necesitaremos 3 elementos principales para implementarlo:

\begin{itemize}
	\item Una cámara que capte imágenes, situada adecuadamente en el AGV.
	
	\item Una ordenador que ejecute el programa.
	
	\item Un elemento para transmitir las instrucciones que genere nuestro programa al sistema de control del vehiculo.
	
\end{itemize}

Tras analizar los diferentes elementos y la forma de combinarlos, podemos obtener dos formas de organización de estos elementos, veamos ambas, y sus ventajas e inconvenienetes.
 

\subsection{Implementación total en el AGV}
En esta implementación se colocarán todos los elementos en el AGV, ejecutando el programa en el ordenador del propio vehículo.
\subsubsection{Ventajas}
\begin{itemize}

	\item No se necesita ningún elemento extra.
	
	\item La transmisión de la imagen y de las instrucciones es inmediata y por conexión física, lo que asegura una buena transmisión de la información.
	
\end{itemize} 

\subsubsection{Desventajas} 
\begin{itemize}

	\item La capacidad de procesamiento del ordenador del vehiculo no es muy grande.
	
	\item Esta implementación dificulta el control simultaneo de varios AGVs.
	
\end{itemize}

\subsection{Externalización del ordenador que ejecuta el programa} 

En esta implementación se externaliza el ordenador donde se ejecuta el programa, a un ordenador fijo, más potente.
\subsubsection{Ventajas}
\begin{itemize}
	\item El ordenador externo nos ofrece mayor capacidad de procesamiento.
	
	\item Poder ver las instrucciones y situación en tiempo real que se están mandando.
	
\end{itemize}

\subsubsection{Desventajas}
\begin{itemize}
	\item Se necesita hardware extra, además del que lleva el AGV.
	
	\item Necesitamos hardware que nos permita un buen flujo de imágenes hacia el ordenador, y una buena transmisión de las instrucciones hacia el vehículo.
	
\end{itemize} 

\section{Procesado de imagen}
Para realizar una detección efectiva de la línea guía en la imagen, tenemos que realizar un procesamiento de la imagen, pasandola por distintos filtros para finalmente obtener la trayectoria que representa la línea guía.

\subsection{Binarización}
Binarizar es el proceso que nos permite distinguir ciertas partes o elementos de una imagen aplicando una serie de valores umbrales. La forma en la que se distinguen los elementos es generando una imagen binaria, donde los elementos destacados tienen un valor, y el resto de la imagen tiene otro valor.
\imagen{img_binaria}{Izquierda, imagen binaria. Derecha imagen real.} 

Primero, tenemos que entender como funciona una pantalla y una cámara, para comprender el formato de imagen más usado actualmente, RGB.

Una imagen RGB está formada por 3 matrices de valores de mismas dimensiones, una matriz para los rojos, otra para los verdes, y otra para los azules (Red-Green-Blue). Este formato, es utilizado actualmente para la representación de imágenes en pantalla, y para la captación de imágenes, ya que se ajusta al formato físico tanto de pantallas como de sensores de cámaras.
Veamos algunos conceptos relacionados con esto:

\begin{itemize}

	\item Pantalla
	
\end{itemize}

Una pantalla está formada por diminutos puntos de color, conocidos como pixeles. Cada pixel tiene 3 "luces", una para rojos, otra para verdes y otra para azules. El formato RGB da a cada una de estas luces un valor, que las hará lucir con mayor o menor intensidad.
\imagen{pixels}{Pixels de una pantalla LCD. Fuente: youtube.com}

La resolución tanto de la pantalla como de la imagen es un aspecto relevante, ya que influirá en la forma en la que la pantalla representará la imagen.
 
La resolución de la pantalla es el número de pixels de ancho, por el número de pixels de alto. La resolución de la imagen es el tamaño de la matriz de ancho, por el tamaño de la matriz de alto.

Cuando ambas son iguales, cada valor de la matriz RGB se interpretará en cada uno de los pixeles de la pantalla. En el caso de que sean diferentes, se hará un reescalado de imagen.

Los valores que pueden tomar son desde 0, apagado, hasta 255, intensidad máxima. La combinación de intensidades de las luces RGB formará los distintos colores. 
\imagen{RGB_rueda}{Combinación de colores RGB. Fuente: wikipedia.org}

Como vemos, tenemos $256^3$ combinaciones diferentes, lo que nos da un rango de 16777216 colores posibles.

\begin{itemize}

	\item Cámara
	
\end{itemize}

La forma de funcionamiento de una cámara se basa en un sensor con celdas sensibles a la luz, que permiten registrar la intensidad con la que incide la luz.
Una vez más, cada una de estas celdas se corresponderá con un una de las luces de un pixel. Para poder registrar los valores RGB se descompone la luz en sus 3 colores primarios, rojo, verde y azul. Se registra la intensidad de cada color, y se genera la imagen RGB.
\imagen{sensor_camara}{Esquema del funcionamiento del sensor de una cámara. Fuente: globalspec.com}

Una vez visto el porqué del formato RGB, podemos empezar a explicar los métodos de binarización.

\subsubsection{Binarización por luminosidad}
Este tipo de binarización consiste en generar una imagen binaria, mediante un umbral aplicado a una imagen donde podamos ver la luminosidad de cada pixel.
Para realizar este tipo de binarización necesitamos una imagen en escala de grises, donde solo tenemos luminosidad. Nuestra cámara nos devuelve imágenes RGB, por lo que debemos realizar una conversión. 

Esta conversión no es algo trivial, ya que los colores primarios de la luz, RGB, no tienen la misma luminosidad. Por lo que la solución mas simple que se nos podría ocurrir, realizar la media para cada pixel de sus valores RGB sería errónea.

En su lugar, debemos corregir la luminosidad de cada matriz de color, para igualar estas diferencias de luminosidad que por propia naturaleza los colores primarios tienen. 

Para ello, multiplicaremos cada matriz por un valor corrector.
Según la documentación de OpenCV\cite{OpenCVRGBGRAY}, la formula que nos permite hacer esta transformación es:

RGB[A] to Gray:$Y=0.299*R+0.587*G+0.114*B$

Donde Y es la imagen resultante.

Una vez obtenemos la imagen en escala de grises, podemos empezar con la binarización.

Para binarizar, primero tenemos que saber cuantos pixels hay de cada valor entre 0 y 255, para tratar de buscar grupos grandes de pixels que compartan valores similares, y así distinguir unos de otros. 

Esta información nos la da el \textbf{histograma de la imagen}.

El histograma de una imagen es la representación de la distribución de los valores de los pixels de la misma.

En el eje X tendremos de izquierda a derecha valores de 0 a 255. En el eje Y de abajo a arriba valores desde 0 hasta en máximo número de pixels encontrados en ese valor de x.

\imagen{img-histograma}{Imagen en escala de grises de la línea guía.}
\imagen{histograma}{Histograma de la Figura 3.5.}

Como podemos apreciar, hay dos picos claros en el histograma, uno correspondiente a la línea guía (pixels oscuros, pico izquierdo del histograma), y el resto correspondientes al fondo blanco (pixels claros, pico derecho del histograma), concuerda con la imágen ya que hay mayor cantidad de pixels claros que de oscuros. El umbral tiene que estar entre ambos picos para diferenciar unos pixels de otros.

La forma más simple que se nos puede ocurrir es la de escoger un valor aleatorio entre ambos picos y entonces, recorrer todos los pixels de la imagen en escala de grises, y a cada pixel asignarle un valor si esta por encima del umbral, u otro valor su esta por debajo.

Esta forma, siendo perfectamente valida, es poco recomendable si trabajamos con flujos de datos continuos, como por ejemplo vídeos, o streamings.
Normalmente en este tipo de flujos de imágenes, la luminosidad puede variar, por lo que el umbral al ser fijo, puede provocar errores en la binarización.

La solución a esto es usar un umbral dinámico, calculado en función del histograma de cada imagen.

La forma que hemos usado para calcular este umbral ha sido mediante el Algoritmo de Otsu\cite{wikiotsu}, ya implementado en OpenCV.

Lo que hace el algoritmo de Otsu es separar la imagen mediante el umbral en dos zonas. Buscamos que la dispersión dentro de cada segmento sea la mínima (que los pixels dentro de ese segmento se parezcan), pero que entre ambos segmentos sea lo máximo posible.

Para esto, inicialmente calcularemos la media aritmética de los valores de gris de toda la imagen, y después solo de cada zona del histograma. Con estos valores podemos calcular las varianzas de cada zona. 

Lo que tenemos que hacer es mantener las variazas de cada zona lo más pequeñas posibles, y conseguir que la varianza entre ambas zonas sea la máxima.

Para conseguir esto, haremos el cociente de la varianza entre las zonas y la suma de las varianzas de cada zona, buscando que este cociente sea el máximo posible. 

Veamoslo de una forma más técnica:

$K_0(t)$ y $K_1(t)$ son las zonas del histograma, separadas por el umbral t.

$p(g)$ es la probabilidad del valor gris g, donde g puede ir desde 0 hasta 255, según el formato de escala de grises que estamos usando.

La probabilidad de ocurrencia para cada zona será:
\begin{itemize}

\item En la zona que va de 0 a t:

$P_0(t)= \sum_{g=0}^{t}p(g)$ 

\item En la zona que va de t+1 hasta 255:

$P_1(t)= \sum_{g=t+1}^{255}p(g)$ o $1-P_0(t)$

\end{itemize}

Siendo $\bar{g}$ la media aritmética de los valores de gris para toda la imagen, y $\bar{g_0}$ y $\bar{g_1}$ la media para cada zona, podemos calcular las varianzas de los segmentos:

\begin{itemize}

\item En la zona que va de 0 a t:

$\sigma{_0^2} = \sum_{g=0}^{t}(g-\bar{g_0})^2p(g)$

\item En la zona que va de t+1 hasta 255:

$\sigma{_1^2} = \sum_{g=t+1}^{255}(g-\bar{g_1})^2p(g)$

\end{itemize}

Ahora necesitaremos las varianzas entre los segmentos, y la suma de la varianza de ambos segmentos.

\begin{itemize}

\item Varianza entre segmentos:

$\sigma{_zw^2} = P_0(t)*(\bar{g_0}-\bar{g})^2 + P_1(t)*(\bar{g_1}-\bar{g})^2$

\item Suma de las varianzas de cada segmento:

$\sigma{_in^2} = P_0(t)*\sigma{_0^2}(t)+P_1(t)*\sigma{_1^2}(t)$

\end{itemize}

Por último, nos queda obtener el cocientre de la varianza entre segmentos y la suma de las varianzas de cada segmento.

$Q(t) = \displaystyle\frac{\sigma{_zw^2}}{\sigma{_in^2}}$

Este es el cociente que tenemos que maximizar. El umbral será el valor de t.

En OpenCV es sencillo hacer este tipo de binarización, ya que contamos con una función que lo realiza instantáneamente, y nos devuelve tanto el umbral que ha usado, como la imagen ya binarizada.

\begin{verbatim}
umbral, img_binaria = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)
\end{verbatim}

Indicamos que queremos hacer la binarización con el algoritmo de Otsu. El valor que se les da a los pixels por debajo del umbral es 0 y el valor por encima es 255. La imagen de origen es img.

El resultado es este:

\imagen{img_bin_otsu}{Resultado de la binarización de la Figura 3.5}

Como vemos, en esta imagen se puede diferenciar perfectamente la línea guía del resto de elementos de la imagen.

\subsubsection{Binarización por color}
Inicialmente, en el formato RGB tenemos colores, pero están separados en 3 matrices diferentes, por lo que es complicado poder binarizar de una forma efectiva. 

Existe in formato de imagen conocido como HSV\cite{hsl_hsv} (Hue, Saturation, Value), donde la matriz H corresponde con los colores puros de la imagen, la matriz S corresponde a los valores de saturación de cada pixel, y la matriz V corresponde con los valores de negro de cada pixel.

Si representamos esto en un prisma, obtenemos:

\imagen{hsv_prism}{Cilindro de colores HSV. Fuente: wikipedia.org}

En este tipo de formato tenemos la posibilidad de quedarnos con un pequeño fragmento del cilindro, dividiéndolo según el valor de H, con lo que podríamos binarizar la imagen según un rango de color concreto.

Veamos como pasar de RGB a HSV.

Lo primero que necesitamos es pasar los valores RGB a un entorno en 2 dimensiones. En RGB además de los 3 colores primarios, tenemos las mezclas de colores primarios, amarillo, magenta y cyan. Si a esto añadimos el color blanco puro, y el color negro puro, obtenemos un cubo. 
Este cubo puede ser representado en 2 dimensiones como un hexágono perfecto, usando como centro del hexágono los vértices de color blanco puro y negro puro. 
Los valores de RGB serán los que determinen la posición del pixel dentro del cubo, la cual será proyectada en dos dimensiones sobre el hexágono.

\imagen{hex_rgb_hsv}{Conversión de RGB a HSV. Fuente: wikipedia.org}

Con esto podemos obtener el ángulo del color de nuestro pixel, H. Como OpenCV trabaja con matrices de valores enteros de 8 bits, no podemos meter en la matriz valores que salgan del rango $[0,255]$ por lo que el ángulo será dividido entre 2, pudiendo estar entre 0 y 180.

El valor de negro, V, es el mayor de los valores RGB. Como OpenCV trabaja con enteros de 8 bits, este valor encaja perfectamtente.

El valor de la saturación, S, se calcula a partir del cubo RGB antes mencionado. Suponemos que el hexágono tiene un radio de 0 a 1. Al representar el color RGB en el plano, estará mas o menos alejado del radio del hexagono, este valor se conoce como Chroma, C. Para calcular la saturación, dividiremos C entre V, lo cual nos dará la saturación. Posteriormente convertiremos este valor en escala de 0 a 255, para que OpenCV pueda trabajar con ello.

Repitiendo este proceso para cada uno de los pixels de la imagen, tendremos nuestra imagen en formato HSV.

Una vez tenemos hecho esto, el proceso de binarización es sencillo. Basta con elegir en la rueda de color el ángulo de los colores que queramos. Para el ángulo 0 tenemos el rojo, 60 amarillo, 120 verde, 180 cyan, 240 azul y 300 magenta. Transformaremos el ángulo para que OpenCV lo interprete adecuadamente, simplemente es dividirlo entre 2.

Una vez tengamos el ángulo del color, estableceremos un margen de seguridad\cite{track_hsv}, para coger todos los pixels con un tono similar. Este margen ha de ser de +10 y -10 para H, y con S y V podemos jugar un poco aunque lo ideal es abarcar el máximo rango posible. Un rango recomendado es entre 100 y 255.

\imagen{img_bin_color}{Resultado de la binarización por color, escogiendo la gama de amarillos.}

En este proyecto se ha simplificado todo este proceso al máximo, ya que es algo complejo. Al usuario se le pedirá calibrar el color mediante unas ventanas de OpenCV, una donde se ve la imagen a color y otra donde se ve el resultado de la binarización. Para elegir un color simplemente tiene que pinchar encima de ese color en la imagen.

Las referencias se incluyen en el texto usando cite \cite{wiki:latex}. Para citar webs, artículos o libros \cite{koza92}.


\section{Transformación de perspectiva}
Como hemos visto en secciones anteriores, la principal funcionalidad buscada en este proyecto es el poder ver la línea guía no solo debajo del AGV, también delante, en perspectiva. Para esto simplemente tenemos que colocar la cámara en una posición determinada, bastante levantada del suelo, y con un ángulo que nos permita ver la máxima perspectiva posible, sin llegar a sobrepasar el horizonte, ya que la información que necesitamos está en el suelo, la línea guía.

El problema de situar la cámara en una posición así, es que no podemos ver las distancias reales en la imagen, puesto que lo estamos viendo todo en perspectiva. Para ver las distancias reales, tendríamos que colocar la cámara paralela al suelo y a una determinada altura, lo cual es complicado. Habría que tener una especie de brazo por delante del robot con la cámara colgando.

Por este motivo, lo que se usa para resolver este problema es una transformación de perspectiva. En concreto, una transformación que, a partir de una imagen tomada desde una situación en la que la cámara forma un cierto ángulo con el suelo, genera una imagen virtual que se vea totalmente paralela al suelo, podríamos llamarlo una "vista de pájaro".

\imagen{bird_view}{Izquierda, vista de pájaro. Derecha, vista original.}

OpenCV no tiene una función especifica para realizar esto, pero tiene una función que permite transformar perspectivas mediante unas coordenadas de origen y unas de destino\citep{persp_trans}. 

Generalmente esta función






\section{Listas de items}

Existen tres posibilidades:

\begin{itemize}
	\item primer item.
	\item segundo item.
\end{itemize}

\begin{enumerate}
	\item primer item.
	\item segundo item.
\end{enumerate}

\begin{description}
	\item[Primer item] más información sobre el primer item.
	\item[Segundo item] más información sobre el segundo item.
\end{description}
	
\begin{itemize}
\item 
\end{itemize}

\section{Tablas}

Igualmente se pueden usar los comandos específicos de \LaTeX o bien usar alguno de los comandos de la plantilla.

\tablaSmall{Herramientas y tecnologías utilizadas en cada parte del proyecto}{l c c c c}{herramientasportipodeuso}
{ \multicolumn{1}{l}{Herramientas} & App AngularJS & API REST & BD & Memoria \\}{ 
HTML5 & X & & &\\
CSS3 & X & & &\\
BOOTSTRAP & X & & &\\
JavaScript & X & & &\\
AngularJS & X & & &\\
Bower & X & & &\\
PHP & & X & &\\
Karma + Jasmine & X & & &\\
Slim framework & & X & &\\
Idiorm & & X & &\\
Composer & & X & &\\
JSON & X & X & &\\
PhpStorm & X & X & &\\
MySQL & & & X &\\
PhpMyAdmin & & & X &\\
Git + BitBucket & X & X & X & X\\
Mik\TeX{} & & & & X\\
\TeX{}Maker & & & & X\\
Astah & & & & X\\
Balsamiq Mockups & X & & &\\
VersionOne & X & X & X & X\\
} 
