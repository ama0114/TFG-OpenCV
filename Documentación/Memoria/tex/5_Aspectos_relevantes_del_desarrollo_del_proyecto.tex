\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

\section{Definición como proyecto de investigación}

Lo primero a destacar es que este proyecto no es un proyecto software común en el que tenemos unos requisitos iniciales mas o menos claros, y tenemos alguna idea del producto final. En este caso lo que buscamos es probar diferentes códigos, herramientas, librerías para satisfacer el requisito principal, la detección de lineas en el suelo. Si conseguimos satisfacer ese requisito, podremos proponer nuevos requisitos en base al resultado obtenido. En definitiva, es más un proyecto enfocado en investigación, pero sin olvidarnos de que tenemos que crear un producto funcional que recoja los resultados de las investigaciones realizadas.

\section{Metodología ágil}
Como antes hemos explicado, este proyecto tiene una gran parte enfocada a la investigación, para adaptar esto a las metodologías ágiles, hemos tenido que:

\begin{itemize}
	\item Modificar la duración de los sprints hasta dar por satisfactoria la investigación realizada en el sprint. 
	\item En base a los resultados de cada investigación, proponer nuevos requisitos, sin tener un objetivo final.
\end{itemize}

Por supuesto, el resto de líneas de trabajo de las metodologías ágiles se han seguido cumpliendo:

\begin{itemize}
	\item Reuniones al finalizar cada sprint.
	\item Organizar tareas en un tablero canvas.
	\item Entregar y realizar una demostración de la investigación al finalizar cada sprint.
\end{itemize}

\section{Relación con conocimientos obtenidos en la carrera}

\subsection{Conocimientos en Python}
Lo primero a destacar es el uso de Python, lenguaje de programación visto en varias asignaturas de la carrera, como Algoritmia, Sistemas Inteligentes o Minería de Datos. 

En estas asignaturas también se han usado algunas de las librerías empleadas en este proyecto, como MatPlotLib o NumPy.


\subsection{Conocimientos de procesamiento de imágenes}
Los conocimientos de algoritmos de visión artificial, se han obtenido en la asignatura de Hardware de Aplicación Específica. Aunque en esta asignatura no se usa OpenCV, sino Matlab, la gran mayoría de funciones que se usan en Matlab para realizar el procesamiento de imagen, tienen una replica exacta en OpenCV.

\subsection{Idea del diario de investigación}
La idea del diario de investigación ha surgido de la asignatura de Fundamentos Físicos de la Informática, en la que usábamos un cuadernillo donde íbamos documentando las diferentes prácticas y los resultados obtenidos. Se puede ver aquí\cite{diario}.

\section{Conocimientos externos a la carrera}

El problema de la transformación de perspectiva es complejo, y no se ha visto durante la carrera, por lo que he tenido que buscar información por internet. La información técnica de este tipo de problemas se sale de los conocimientos propios de un informático, están más destinados a personas especializadas en Óptica, aún así, hay tutoriales y otros proyectos donde se trata este tipo de problema desde un punto más amigable para un informático. 

Un tutorial que me ayudo a comprender como realizar la transformación de perspectiva es este\cite{coord_persp}. Aunque en ese tutorial colocan la cámara viendo por encima del horizonte y tienen que realizar unos ajustes extra para obtener la vista solo desde el horizonte hacia abajo. Aun así tiene conceptos como el de reducir la parte inferior de la imagen, que han sido usados en este proyecto.



\section{Restricciones del proyecto}



No tenemos que olvidar que el fin último de este proyecto es implementarlo en un entorno industrial, donde todo tiene que estar meticulosamente controlado. 

Un requisito importante que se impuso desde el principio del proyecto es que un AGV necesita recibir una instrucción cada 2 centésimas de segundo, realizando una operación simple, obtenemos que necesitamos procesar 50 imágenes por segundo para poder satisfacer este requisito.

El hardware con el que cuento no es demasiado potente, ni esta específicamente diseñado para cumplir este requisito, como si lo estaría en una implementación real. Aun así, al principio del proyecto se realizaron unas pruebas de resolución y calidad de imagen, en busca de esta tasa de fotogramas.

Los resultados se muestran en las tablas: Tabla 5.4, Tabla 5.5 y Tabla 5.6.

Una vez obtenida la tasa de frames deseada, se empezó con la siguiente fase del proyecto.

\tablaSmall{Resolucion 800x600 y Fps}{l c c c}{resolucion_fps800600}
{ \multicolumn{1}{l}{Calidad streaming} & Min Fps &  Max Fps & Media Fps\\}{ 
100 & 1.43 & 6.85 & 3.82\\
75 & 4.67 & 16.13 & 11.49\\
50 & 2.15 & 19.23 & 12.04\\
}

\tablaSmall{Resolucion 640x480 y Fps}{l c c c}{resolucion_fps640480}
{ \multicolumn{1}{l}{Calidad streaming} & Min Fps &  Max Fps & Media Fps\\}{ 
100 & 2.28 & 7.3 & 5.57\\
75 & 1.07 & 23.26 & 15.73\\
50 & 2.47 & 22.73 & 16.13\\
}

\tablaSmall{Resolucion 176x144 y Fps}{l c c c}{resolucion_fps176144}
{ \multicolumn{1}{l}{Calidad streaming} & Min Fps &  Max Fps & Media Fps\\}{ 
20 & 5.26 & 200.00 & 58.20\\
}

\section{Fases del proyecto}
Las fases de este proyecto partían de un requisito a cumplir, realizando un trabajo de investigación, y posteriormente generando una implementación y realizando pruebas en el entorno. 

\subsection{Binarización}
\subsubsection{Binarizacion por luminosidad}
Inicialmente se planteó la binarización por luminosidad, se investigaron diferentes algoritmos como Otsu, Umbral Adaptativo por Vecindad y Umbral fijo, siendo el más efectivo el algoritmo de Otsu. 

Las pruebas realizadas tenían estos requisitos a cumplir:

\begin{itemize}

	\item Que la tasa de Fps fuera adecuada, todos lo consiguieron.
	
	\item Que la binarización fuera correcta, Otsu y umbral fijo lo consiguieron. Los algoritmos de Umbrales adaptativo por Vecindad, tanto Media como Gaussiano, generaban ciertas distorsiones en la imagen.
	
	\item Que fueran robustos frente a variaciones de luminosidad, solo Otsu consiguió esto. Umbral fijo, como su propio nombre indica, no era capaz de modificar el umbral de binarización, por lo que a partir de cierta luminosidad, la binarización era erronea.
\end{itemize}

El algoritmo de umbral fijo no era capaz de aguantar la variación de luminosidad. 

El algoritmo de Umbral Adaptativo por Vecindad no está preparado para este tipo de problemas, está enfocado a usarse en imágenes donde la luz incide de forma desigual, siendo capaz de calcular un umbral en función de la luminosidad de los vecinos del pixel que se este procesando.

El algoritmo de Otsu calcula el umbral en función de la luminosidad de la imagen, lo cual es ideal para este proyecto ya que se puede adaptar a las variaciones de iluminación. En la versión final del proyecto, se muestra tanto la luminosidad de la imagen, como el umbral de Otsu que se está usando para binarizar la imagen.

Es por esto, que nos quedamos con el algoritmo de Otsu.

\imagen{lum_umbral}{Pantalla donde se muestra tanto la luminisdad de la imagen como el umbral de binarizacion generado por el algoritmo de Otsu.}

Bajo la experiencia de todas las pruebas realizadas, la luminosidad medida de está forma puede llegar a bajar hasta a valores de 2, donde prácticamente toda la imagen es negra, y llegar hasta valores de 200, donde la imagen es blanca entera. Llegar a generar una imagen en un entorno real donde la cámara capte el color blanco puro es prácticamente imposible, por esto nunca llegaremos a acercarnos a valores de 255. 

\subsubsection{Binarizacion por color}

En etapas más avanzadas del proyecto se probó la binarización por color, mediante el formato de imagen HSV obteniendo buenos resultados, y una implementación más realista, de cara a que no es necesario que el fondo donde se coloca la imagen sea uniforme, sino que puede ser de cualquier tipo, siempre que no sea del mismo color o similar que la linea que intentamos detectar. Aun así este tipo de binarización es mucho más sensible a las variaciones de luz, por lo que también tiene esa desventaja.

\subsection{Transofmación de perspectiva}
Para realizar esto primero se implementaron unas funciones que tenían cierta lógica, pero no acabaron funcionando como se esperaba, aunque sirvieron como punto de partida para usar algunas de las otras funciones que OpenCV tiene para resolver este problema.

\subsubsection{Función inicial}

Inicialmente se creó una función que solo trabajaba con imágenes binarizadas. Lo que hacía era mediante la plantilla del cuadrado, calculaba un "coeficiente de reducción" que servía para saber la cantidad de pixels a reducir en cada fila de la imagen. 

Lo que hacemos es a partir del trapecio que se genera al ver el cuadrado en perspectiva, calcular la diferencia entre su base, en la imagen tamaño máximo, y su lado superior, en la imagen, tamaño deseado. 

\imagen{trap}{Esquema de medidas para generar un cuadrado a partir de un trapecio.}

Esta diferencia es la que tenemos que "solventar" para hacer que sean iguales, y por tanto un cuadrado. 
El trapecio está formado por filas de pixels, por lo que podemos dividir esa diferencia en pixels de los lados, entre el número de filas que tiene de alto el trapecio, lo que nos dará la cantidad de pixels que tenemos que reducir en cada fila.

Por ejemplo en la fila 0, la del lado menor del trapecio, tendremos que reducir 0 * coeficiente de reduccion, 0 pixels. Concuerda, puesto que el tamaño buscado es el de esa misma fila.

Para la fila de la base, tendremos que reducir el número de fila donde se encuentre (altura del trapecio) * coeficiente, lo que nos dará exactamente la diferencia entre los dos lados antes calculada, dejando del mismo tamaño el lado superior e inferior.

Las filas del medio del trapecio seguirán el mismo algoritmo, dejando a todas iguales al lado menor del trapecio, y por tanto dejándolo en forma cuadrada.

Este algoritmo a pesar de que funciona, tiene un problema y es que no guarda la relación de aspecto de los objetos del mundo real. El cuadrado que debería ser cuadrado, es rectangular, a si que no nos vale.

Pero lo que si hemos conseguido es un algoritmo capaz de generar un coeficiente único para cada ángulo que forma la cámara con el suelo.

\subsubsection{Funcion de transformación de perspectiva de OpenCV}

Una vez podemos distinguir el ángulo con el que estamos, podemos relacionar este ángulo con las funciones de OpenCV, pudiendo generar una transformación de perspectiva única y adecuada para cada ángulo.

\subsection{Obtener la trayectoria}
Esta fase es la más inmediata, solo necesitamos los bordes de la línea con la distorsión por perspectiva resuelta, y obtener el punto medio entre los bordes.

Una vez generada la trayectoria, se pueden aplicar diferentes métodos para estimar el polinomio capaz de adaptarse a la forma que tenga la trayectoria.


\subsection{Sistema de guiado}
Aunque lo ideal es recrear virtualmente el entorno donde está el vehículo, como hemos visto en secciones anteriores, esta funcionalidad es realmente compleja y se escapa del ámbito de este proyecto. Aun así, se puede generar un sistema de guiado básico, con la parte más cercana de la trayectoria que tiene el vehículo. 

La idea inicial era hacer un sistema que simplemente nos dijera si estamos a la izquierda o a la derecha de la trayectoria, pero finalmente se añadieron las funcionalidades del calculo del ángulo de giro en función de la desviación, y el margen de seguridad donde permitimos que el robot siga recto aunque no este exactamente sobre la trayectoria, corrigiendole cuando se salga de este margen.

\section{Pruebas}
En cada fase se han realizado pruebas y se han dejado expuestas en vídeos en el repositorio.

Las pruebas están organizadas según la investigación:

\begin{itemize}
	\item Una prueba inicial con el objetivo de obtener 50 Fps. Se trabajará en el entorno habitual, en esta etapa no teníamos la función de luminosidad por lo que no hay medidas de esta, pero teníamos la suficiente luminosidad como para que la cámara obtuviera la máxima tasa de Fps, y la imagen fuera perfectamente visible.
	
Lo que se ha ido haciendo es modificar la resolución y calidad de la imagen hasta que hemos obtenido la tasa de frames deseada, 50 fps. Esta tasa se ha alcanzado en la prueba de resolución 176x144, con una calidad del streaming 20.

El parámetro que vamos a medir es la tasa de Fps.

La Resolución de la imagen y la calidad del vídeo se modificarán según se especifica en el nombre de cada prueba. 

Podemos verlas en los siguientes vídeos:
	
	\href{https://youtu.be/r73s9I_8SiI}{Resolución 800x600 calidad 50}
	
	\href{https://youtu.be/rdv0COnl-G4}{Resolución 800x600 calidad 75}
	
	\href{https://youtu.be/tGip7sWjD8E}{Resolución 800x600 calidad 100}
	
	\href{https://youtu.be/saFDDQNjsEs}{Resolución 640x480 calidad 50}
	
	\href{https://youtu.be/a3ZxLQB37k0}{Resolución 640x480 calidad 75}
	
	\href{https://youtu.be/zu8rWr31fuQ}{Resolución 640x480 calidad 100}
	
	\href{https://youtu.be/WzJjXKeKpaI}{Resolución 176x144 calidad 20}	
	
	\item Pruebas de luminosidad, en busca de implementar una función que calcule la luminosidad de la imagen. 

El parámetro a medir es la luminosidad, en concreto medida con la
función implementada en esta etapa.

En este caso hemos modificado la luminosidad del ambiente en el que se encontraba la cámara para ver como la función se comportaba. El resultado esperado era que el valor que devolvía la función disminuyera acorde con la disminución de luminosidad, y aumentara cuando la luminosidad del entorno aumentara. El resultado es satisfactorio, ya que cumple perfectamente este funcionamiento.
	
	Podemos verla en el siguiente vídeo:
	
	\href{https://youtu.be/CuTADdioU4g}{Prueba de la función que calcula la luminosidad}	
	
	\item Pruebas de binarización, tanto por luminosidad como por color. 
	
	En las pruebas de binarización por luminosidad el entorno está formado por un fondo blanco y una cinta aislante negro.
	
En las pruebas de binarización por color el entorno es un tapete de color verde oscuro, y la línea de cartulina amarilla, con el borde remarcado en cinta aislante.

Buscaremos la mayor pureza de imagen posible, que no contenga
distorsiones ni partes mal binarizadas. Podemos ver esto en la previsualización de la binarización.

La funcionalidad buscada en esta prueba es la de obtener una función que se comportara bien a la hora de binarizar. Hemos encontrado dos funciones capaces de esto, binarización mediante el algoritmo de Otsu, poco sensible a las variaciones de luminosidad, y binarización por color, sensible a las variaciones de luminosidad.

En condiciones de luminosidad constante, ambas funciones se comportan bien.

Destacar que mientras que en la binarización por luminosidad, el fondo blanco donde está la línea, no puede sufrir distorsión alguna, ya que aparecerían desperfectos en la imagen, en la binarización por color si podemos tener un fondo de muy diversa indole, siempre y cuando no sea del mismo color o parecido al color de la línea.
	
	
	Podemos verlas en los siguientes vídeos:
	
	\href{https://youtu.be/Gu_HvPr3cCU}{Binarizar con umbral fijo}
	
	\href{https://youtu.be/NCWQ2I-1J_o}{Binarizar con umbral adaptativo de vecindad Media}
	
	\href{https://youtu.be/XPxqk3kNXKY}{Binarizar con umbral adaptativo de vecindad Gausiano}
	
	\href{https://youtu.be/4CW4r9qdo4Y}{Binarizar por luminosidad con Otsu}
	
	\href{https://youtu.be/Rks5PkxDeZQ}{Binarizar por color}
	
	\item Prueba de calculo del coefciente para resolver la distorsión de perspectiva. 
	
	En este caso el entorno será la línea guía, y lo que modificaremos será el ángulo de la cámara.
	
El parámetro a medir será el coeficiente que devuelva la función.

En esta prueba lo que buscamos es realizar un test y anotaciones de los diferentes coeficientes que devuelve la función que calcula el coeficiente para relacionarlo con el ángulo que tiene la cámara respecto del suelo.
	
	Podemos verla en el siguiente vídeo: 
	
	\href{https://youtu.be/Y9QgFIMXSiU}{Prueba de calculo del coeficiente}
	
	
	\item Pruebas de la resolución de la distorsión de perspectiva. 
	
	En este caso mediremos el ancho de la línea.
	
El entorno es el habitual, linea de cinta aislante negro sobre fondo blanco.

El parámetro a medir es el ancho de la línea en pixels, para ello
usaremos la herramienta Online Pixel Ruler.

Tomamos medidas de en la imagen para preparar el algoritmo.

Una vez pensado el algoritmo, elegimos una fila cualquiera, la 70 por ejemplo y realizamos mediciones en la imagen para comprobar que el algoritmo está bien diseñado. El algoritmo es el que se menciona en la Figura 5.26.

	
	Podemos verlas en los siguientes vídeos:
	
	\href{https://youtu.be/rUQrHbA_H8A}{Tomar medidas del ancho de la línea}
	
	\href{https://youtu.be/ClA-Ei8f18o}{Comprobar medidas de la linea}
	
	\item Medida del ancho de línea variando luminosidad
	
	En esta prueba comprobamos como afecta la variación de luminosidad en la binarización por luminosidad a la medida del ancho de la línea.
Se variará la luminosidad del entorno.

El parametro a medir es el ancho de la línea.
	
	\href{https://youtu.be/m7t4dcfuFeo}{Prueba a medir el ancho variando la luminosidad}
	
	\item Primera comprobación de la transformación de perspectiva
	
	En esta prueba simplemente buscamos ver a ojo si la función de transformación de perspectiva es capaz de modificar la imagen, buscando realizar la correción de la distorsión.
	
Para ello colocaremos la cámara en distintos ángulos y ejecutaremos las funciones de corrección.
	
	\href{https://youtu.be/pRE8zerfp7E}{Primera comprobación de la resolución de distorsión por perspectiva}
	
	\item Encontrar la trayectoria
	
	En esta prueba lo que buscamos es obtener la trayectoria (punto medio entre los dos bordes de la línea).
	
El entorno es el habitual, línea guía de cinta aislante negro sobre fondo blanco.

Usaremos las funciones del coeficiente y de la transformación de la imagen. Variaremos la imagen moviendo la cámara.

El resultado esperado es que la línea guía se ve en dos dimensiones, que podamos ver tanto sus bordes como la trayectoria.

	
	\href{https://youtu.be/Ae5aTr3mg6k}{Encontrar la trayectoria con la distorsión resuelta}
	
	\item Comprobación de proporciones reales
	
	En esta prueba buscamos comprobar que la imagen resultante de la transformación por perspectiva guarda las mismas dimensiones que la realidad.
	
Para ello se ha creado una plantilla con ángulos, de cinta aislante negro sobre fondo blanco.

Colocaremos la plantilla delante de la cámara, tras haber ejecutado las funciones de corrección de distorsión de perspectiva.

Mediremos los ángulos en la imagen, con ayuda de LightShot, un programa para hacer capturas de pantalla, que permite dibujar sobre esta, permitiendo agrandar los ángulos de la imagen. Usaremos finalmente un transportador de ángulos para medir el ángulo sobre la pantalla.

El resultado es satisfactorio, midiendo el mismo ángulo en la imagen y en la realidad.
	
	\href{https://youtu.be/wc00piNmfyI}{Comprobar que la imagen corregida guarda las proporciones de la realidad midiendo ángulos 1.}
	
	\href{https://youtu.be/T0djIwql6G8}{Comprobar que la imagen corregida guarda las proporciones de la realidad midiendo ángulos 2.}
	
	\item Pruebas del sistema de guiado. 
	
	En estas pruebas lo que hacemos es calcular la trayectoria en la imagen sin resolver la distorsión de perspectiva. Buscamos el encontrar la trayectoria para poder ver si la trayectoria está más a la derecha o a la izquierda del centro de la imagen. Esto nos permitirá guiar al vehículo. 
	
	Modificaremos la posición de la cámara para ver como afecta al programa.
	
El parámetro a revisar es el ángulo que genera la función de guía, y el indicador de dirección.

En estas pruebas vemos que el sistema de guiado se comporta de la forma esperada, por lo que son satisfactorias.	
	
	Podemos verlas en los siguientes vídeos:
	
	\href{https://youtu.be/ODr3q91MLk0}{Prueba del sistema de guiado}
	
	\href{https://youtu.be/8j69cDydXfA}{Sistema de guiado final con todos los elementos visualizables}
	
	
\end{itemize}

La función de luminosidad se ha usado en todas las etapas de procesado de la imagen, para saber las condiciones del entorno y poder reproducir la prueba bajo las mismas condiciones.
